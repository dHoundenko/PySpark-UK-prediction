{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-08T18:41:05.593906Z",
     "start_time": "2023-05-08T18:41:04.216883Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import VectorAssembler and Vectors\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "# Imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import functions as f\n",
    "from pyspark.sql.functions import udf, StringType, col, when, max, min, rand, hour, minute, expr\n",
    "from pyspark.sql import SparkSession, functions as F\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import OneHotEncoder, VectorAssembler, StringIndexer\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-08T18:41:15.024097Z",
     "start_time": "2023-05-08T18:41:06.126360Z"
    }
   },
   "outputs": [],
   "source": [
    "# Building session now\n",
    "spark = SparkSession.builder.appName('ML_with_spark').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-08T18:49:21.319034Z",
     "start_time": "2023-05-08T18:43:16.838508Z"
    }
   },
   "outputs": [],
   "source": [
    "df1 = spark.read.csv('/mnt/bdpa23-group14-pvc/accidents_2005_to_2007.csv', header=True, inferSchema=True)\n",
    "df2 = spark.read.csv('/mnt/bdpa23-group14-pvc/accidents_2009_to_2011.csv', header=True, inferSchema=True)\n",
    "df3 = spark.read.csv('/mnt/bdpa23-group14-pvc/accidents_2012_to_2014.csv', header=True, inferSchema=True)\n",
    "# Combine the DataFrames into a single DataFrame\n",
    "data = df1.union(df2).union(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-08T18:49:22.221955Z",
     "start_time": "2023-05-08T18:49:21.322835Z"
    }
   },
   "outputs": [],
   "source": [
    "data = data.drop(\"Junction_Detail\")\n",
    "data = data.drop(\"Junction_Control\")\n",
    "data = data.drop(\"LSOA_of_Accident_Location\")\n",
    "data = data.withColumnRenamed(\"Local_Authority_(District)\", \"Local_Authority_District\")\n",
    "data = data.withColumnRenamed(\"Local_Authority_(Highway)\", \"Local_Authority_Highway\")\n",
    "data = data.withColumnRenamed(\"Pedestrian_Crossing-Human_Control\", \"Pedestrian_Crossing_Human_Control\")\n",
    "data = data.withColumnRenamed(\"Pedestrian_Crossing-Physical_Facilities\", \"Pedestrian_Crossing_Physical_Facilities\")\n",
    "data = data.dropna(how='any', thresh=None, subset=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-08T18:52:31.061672Z",
     "start_time": "2023-05-08T18:52:03.922744Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1275966\n",
      "204119\n",
      "19415\n"
     ]
    }
   ],
   "source": [
    "df = data\n",
    "# separate the dataframe into two based on the labels\n",
    "df_majority = df.filter(col(\"Accident_Severity\") == 3)\n",
    "df_minority_1 = df.filter(col(\"Accident_Severity\") == 2)\n",
    "df_minority_2 = df.filter(col(\"Accident_Severity\") == 1)\n",
    "majority = df_majority.count()\n",
    "minority_1 = df_minority_1.count()\n",
    "minority_2 = df_minority_2.count()\n",
    "print(majority)\n",
    "print(minority_1)\n",
    "print(minority_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-08T18:58:18.076297Z",
     "start_time": "2023-05-08T18:58:18.071069Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15997213091884893 10.51346896729333\n"
     ]
    }
   ],
   "source": [
    "# Downsample frequent classes\n",
    "ratio_majority = float(minority_1 / majority)\n",
    "ratio_minority_2 = float(minority_1 / minority_2)\n",
    "print(ratio_majority, ratio_minority_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-08T18:58:37.090560Z",
     "start_time": "2023-05-08T18:58:18.772551Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203547\n",
      "203954\n",
      "204119\n"
     ]
    }
   ],
   "source": [
    "# Resample to get balanced data between classes\n",
    "df_oversampled_minority_2 = df_minority_2.sample(True, ratio_minority_2, seed=42)\n",
    "df_undersampled_majority = df_majority.sample(False, ratio_majority, seed=42)\n",
    "print(df_undersampled_majority.count())\n",
    "print(df_oversampled_minority_2.count())\n",
    "print(df_minority_1.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-08T19:06:15.078919Z",
     "start_time": "2023-05-08T19:06:15.050779Z"
    }
   },
   "outputs": [],
   "source": [
    "# Combine into a new dataframe\n",
    "balanced_df = df_oversampled_minority_2.union(df_undersampled_majority).union(df_minority_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-08T19:06:19.109333Z",
     "start_time": "2023-05-08T19:06:19.082613Z"
    }
   },
   "outputs": [],
   "source": [
    "#functions\n",
    "def get_string_mapping(col_name, dataframe):\n",
    "    print(\"Getting mapping\")\n",
    "    unique_strings = [row[0] for row in dataframe.select(col_name).distinct().collect()]\n",
    "    mapping = dict(zip(unique_strings, range(len(unique_strings))))\n",
    "    return mapping\n",
    "\n",
    "def get_embedding(col_name, mapping, dataframe):\n",
    "    print(\"Getting embedding\")\n",
    "    when_expr = reduce(lambda a, b: a.when(dataframe[col_name] == b, mapping[b]),\n",
    "                       mapping, when(dataframe[col_name].isNull(), None))\n",
    "    dataframe = dataframe.withColumn(col_name + \"_embedded\", when_expr)\n",
    "    dataframe = dataframe.drop(col_name)\n",
    "    dataframe = dataframe.withColumnRenamed(col_name + \"_embedded\", col_name)\n",
    "    return dataframe\n",
    "\n",
    "def normalize_column(col_name, dataframe):\n",
    "    print(\"Normalizing\")\n",
    "    max_value = dataframe.select(max(col_name)).collect()[0][0]\n",
    "    dataframe = dataframe.withColumn(f\"{col_name}_normalized\", expr(\"{} / {}\".format(col_name, max_value))).drop(col_name)\n",
    "    dataframe = dataframe.withColumnRenamed(col_name + \"_normalized\", col_name)\n",
    "    return dataframe \n",
    "\n",
    "def embed_time(df):\n",
    "    print(\"Embedding time\")\n",
    "    # Convert to seconds since midnight\n",
    "    df = df.withColumn('Time', hour('Time') * 3600 + minute('Time') * 60)\n",
    "    return df\n",
    "\n",
    "def get_col_names(df):\n",
    "    col_names = []\n",
    "    for col in df.dtypes:\n",
    "        col_names.append((col[0], col[1]))\n",
    "    return col_names\n",
    "\n",
    "def normalize_column_2(col_name, dataframe):\n",
    "    max_value = dataframe.select(max(col_name)).collect()[0][0]\n",
    "    min_value = dataframe.select(min(col_name)).collect()[0][0]\n",
    "    diff = max_value - min_value\n",
    "    dataframe = dataframe.withColumn(f\"{col_name}_normalized\",\n",
    "                                     expr(\"(({} - {}) / {}) * 2 - 1\".format(col_name, min_value, diff))).drop(col_name)\n",
    "    dataframe = dataframe.withColumnRenamed(col_name + \"_normalized\", col_name)\n",
    "    return dataframe \n",
    "def handle_dataframe(df):\n",
    "    df_cols = get_col_names(df)\n",
    "    print(\"Starting dataframe handling\")\n",
    "    for col in df_cols:\n",
    "        col_name = col[0]\n",
    "     \n",
    "        if col_name == \"Accident_Severity\":\n",
    "            df = df.withColumnRenamed(\"Accident_Severity\", \"label\")\n",
    "        elif col_name == \"Accident_Index\":\n",
    "            pass\n",
    "        else:\n",
    "            print(f\"Handling {col_name}\")\n",
    "            if col[1] == 'string':\n",
    "                if col_name == \"Time\":\n",
    "                    df = embed_time(df)\n",
    "                else:\n",
    "                    mapping = get_string_mapping(col_name, df)\n",
    "                    df = get_embedding(col_name, mapping, df)\n",
    "                    \n",
    "            df = normalize_column_2(col_name, df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-08T19:16:24.098256Z",
     "start_time": "2023-05-08T19:06:20.729466Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting dataframe handling\n",
      "Handling Location_Easting_OSGR\n",
      "Handling Location_Northing_OSGR\n",
      "Handling Longitude\n",
      "Handling Latitude\n",
      "Handling Police_Force\n",
      "Handling Number_of_Vehicles\n",
      "Handling Number_of_Casualties\n",
      "Handling Date\n",
      "Getting mapping\n",
      "Getting embedding\n",
      "Handling Day_of_Week\n",
      "Handling Time\n",
      "Embedding time\n",
      "Handling Local_Authority_District\n",
      "Handling Local_Authority_Highway\n",
      "Getting mapping\n",
      "Getting embedding\n",
      "Handling 1st_Road_Class\n",
      "Handling 1st_Road_Number\n",
      "Handling Road_Type\n",
      "Getting mapping\n",
      "Getting embedding\n",
      "Handling Speed_limit\n",
      "Handling 2nd_Road_Class\n",
      "Handling 2nd_Road_Number\n",
      "Handling Pedestrian_Crossing_Human_Control\n",
      "Getting mapping\n",
      "Getting embedding\n",
      "Handling Pedestrian_Crossing_Physical_Facilities\n",
      "Getting mapping\n",
      "Getting embedding\n",
      "Handling Light_Conditions\n",
      "Getting mapping\n",
      "Getting embedding\n",
      "Handling Weather_Conditions\n",
      "Getting mapping\n",
      "Getting embedding\n",
      "Handling Road_Surface_Conditions\n",
      "Getting mapping\n",
      "Getting embedding\n",
      "Handling Special_Conditions_at_Site\n",
      "Getting mapping\n",
      "Getting embedding\n",
      "Handling Carriageway_Hazards\n",
      "Getting mapping\n",
      "Getting embedding\n",
      "Handling Urban_or_Rural_Area\n",
      "Handling Did_Police_Officer_Attend_Scene_of_Accident\n",
      "Getting mapping\n",
      "Getting embedding\n",
      "Handling Year\n",
      "-RECORD 0-----------------------------------------------------------\n",
      " Accident_Index                              | 200501CP00085        \n",
      " label                                       | 1                    \n",
      " Location_Easting_OSGR                       | 0.5825005927983469   \n",
      " Location_Northing_OSGR                      | -0.7136481876404006  \n",
      " Longitude                                   | 0.5996622544922321   \n",
      " Latitude                                    | -0.7035259797227147  \n",
      " Police_Force                                | -0.03092783505154... \n",
      " Number_of_Vehicles                          | -0.9696969696969697  \n",
      " Number_of_Casualties                        | -0.9782608695652174  \n",
      " Date                                        | -0.8831050228310502  \n",
      " Day_of_Week                                 | 0.0                  \n",
      " Time                                        | 0.5424200278164117   \n",
      " Local_Authority_District                    | 0.21063829787234045  \n",
      " Local_Authority_Highway                     | 0.12621359223300965  \n",
      " 1st_Road_Class                              | -0.19999999999999996 \n",
      " 1st_Road_Number                             | -0.9996              \n",
      " Road_Type                                   | -0.6                 \n",
      " Speed_limit                                 | -0.33333333333333337 \n",
      " 2nd_Road_Class                              | 0.7142857142857142   \n",
      " 2nd_Road_Number                             | -0.9998              \n",
      " Pedestrian_Crossing_Human_Control           | -1.0                 \n",
      " Pedestrian_Crossing_Physical_Facilities     | 1.0                  \n",
      " Light_Conditions                            | -1.0                 \n",
      " Weather_Conditions                          | 0.5                  \n",
      " Road_Surface_Conditions                     | 0.5                  \n",
      " Special_Conditions_at_Site                  | -0.7142857142857143  \n",
      " Carriageway_Hazards                         | -1.0                 \n",
      " Urban_or_Rural_Area                         | -1.0                 \n",
      " Did_Police_Officer_Attend_Scene_of_Accident | 1.0                  \n",
      " Year                                        | -1.0                 \n",
      "-RECORD 1-----------------------------------------------------------\n",
      " Accident_Index                              | 200501CP00085        \n",
      " label                                       | 1                    \n",
      " Location_Easting_OSGR                       | 0.5825005927983469   \n",
      " Location_Northing_OSGR                      | -0.7136481876404006  \n",
      " Longitude                                   | 0.5996622544922321   \n",
      " Latitude                                    | -0.7035259797227147  \n",
      " Police_Force                                | -0.03092783505154... \n",
      " Number_of_Vehicles                          | -0.9696969696969697  \n",
      " Number_of_Casualties                        | -0.9782608695652174  \n",
      " Date                                        | -0.8831050228310502  \n",
      " Day_of_Week                                 | 0.0                  \n",
      " Time                                        | 0.5424200278164117   \n",
      " Local_Authority_District                    | 0.21063829787234045  \n",
      " Local_Authority_Highway                     | 0.12621359223300965  \n",
      " 1st_Road_Class                              | -0.19999999999999996 \n",
      " 1st_Road_Number                             | -0.9996              \n",
      " Road_Type                                   | -0.6                 \n",
      " Speed_limit                                 | -0.33333333333333337 \n",
      " 2nd_Road_Class                              | 0.7142857142857142   \n",
      " 2nd_Road_Number                             | -0.9998              \n",
      " Pedestrian_Crossing_Human_Control           | -1.0                 \n",
      " Pedestrian_Crossing_Physical_Facilities     | 1.0                  \n",
      " Light_Conditions                            | -1.0                 \n",
      " Weather_Conditions                          | 0.5                  \n",
      " Road_Surface_Conditions                     | 0.5                  \n",
      " Special_Conditions_at_Site                  | -0.7142857142857143  \n",
      " Carriageway_Hazards                         | -1.0                 \n",
      " Urban_or_Rural_Area                         | -1.0                 \n",
      " Did_Police_Officer_Attend_Scene_of_Accident | 1.0                  \n",
      " Year                                        | -1.0                 \n",
      "-RECORD 2-----------------------------------------------------------\n",
      " Accident_Index                              | 200501CP00085        \n",
      " label                                       | 1                    \n",
      " Location_Easting_OSGR                       | 0.5825005927983469   \n",
      " Location_Northing_OSGR                      | -0.7136481876404006  \n",
      " Longitude                                   | 0.5996622544922321   \n",
      " Latitude                                    | -0.7035259797227147  \n",
      " Police_Force                                | -0.03092783505154... \n",
      " Number_of_Vehicles                          | -0.9696969696969697  \n",
      " Number_of_Casualties                        | -0.9782608695652174  \n",
      " Date                                        | -0.8831050228310502  \n",
      " Day_of_Week                                 | 0.0                  \n",
      " Time                                        | 0.5424200278164117   \n",
      " Local_Authority_District                    | 0.21063829787234045  \n",
      " Local_Authority_Highway                     | 0.12621359223300965  \n",
      " 1st_Road_Class                              | -0.19999999999999996 \n",
      " 1st_Road_Number                             | -0.9996              \n",
      " Road_Type                                   | -0.6                 \n",
      " Speed_limit                                 | -0.33333333333333337 \n",
      " 2nd_Road_Class                              | 0.7142857142857142   \n",
      " 2nd_Road_Number                             | -0.9998              \n",
      " Pedestrian_Crossing_Human_Control           | -1.0                 \n",
      " Pedestrian_Crossing_Physical_Facilities     | 1.0                  \n",
      " Light_Conditions                            | -1.0                 \n",
      " Weather_Conditions                          | 0.5                  \n",
      " Road_Surface_Conditions                     | 0.5                  \n",
      " Special_Conditions_at_Site                  | -0.7142857142857143  \n",
      " Carriageway_Hazards                         | -1.0                 \n",
      " Urban_or_Rural_Area                         | -1.0                 \n",
      " Did_Police_Officer_Attend_Scene_of_Accident | 1.0                  \n",
      " Year                                        | -1.0                 \n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = handle_dataframe(balanced_df)\n",
    "data.show(3, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-08T19:18:56.831230Z",
     "start_time": "2023-05-08T19:18:56.796881Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Accident_Index',\n",
       " 'label',\n",
       " 'Location_Easting_OSGR',\n",
       " 'Location_Northing_OSGR',\n",
       " 'Longitude',\n",
       " 'Latitude',\n",
       " 'Police_Force',\n",
       " 'Number_of_Vehicles',\n",
       " 'Number_of_Casualties',\n",
       " 'Date',\n",
       " 'Day_of_Week',\n",
       " 'Time',\n",
       " 'Local_Authority_District',\n",
       " 'Local_Authority_Highway',\n",
       " '1st_Road_Class',\n",
       " '1st_Road_Number',\n",
       " 'Road_Type',\n",
       " 'Speed_limit',\n",
       " '2nd_Road_Class',\n",
       " '2nd_Road_Number',\n",
       " 'Pedestrian_Crossing_Human_Control',\n",
       " 'Pedestrian_Crossing_Physical_Facilities',\n",
       " 'Light_Conditions',\n",
       " 'Weather_Conditions',\n",
       " 'Road_Surface_Conditions',\n",
       " 'Special_Conditions_at_Site',\n",
       " 'Carriageway_Hazards',\n",
       " 'Urban_or_Rural_Area',\n",
       " 'Did_Police_Officer_Attend_Scene_of_Accident',\n",
       " 'Year']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-08T19:18:59.791774Z",
     "start_time": "2023-05-08T19:18:59.782117Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Accident_Index: string (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      " |-- Location_Easting_OSGR: double (nullable = true)\n",
      " |-- Location_Northing_OSGR: double (nullable = true)\n",
      " |-- Longitude: double (nullable = true)\n",
      " |-- Latitude: double (nullable = true)\n",
      " |-- Police_Force: double (nullable = true)\n",
      " |-- Number_of_Vehicles: double (nullable = true)\n",
      " |-- Number_of_Casualties: double (nullable = true)\n",
      " |-- Date: double (nullable = true)\n",
      " |-- Day_of_Week: double (nullable = true)\n",
      " |-- Time: double (nullable = true)\n",
      " |-- Local_Authority_District: double (nullable = true)\n",
      " |-- Local_Authority_Highway: double (nullable = true)\n",
      " |-- 1st_Road_Class: double (nullable = true)\n",
      " |-- 1st_Road_Number: double (nullable = true)\n",
      " |-- Road_Type: double (nullable = true)\n",
      " |-- Speed_limit: double (nullable = true)\n",
      " |-- 2nd_Road_Class: double (nullable = true)\n",
      " |-- 2nd_Road_Number: double (nullable = true)\n",
      " |-- Pedestrian_Crossing_Human_Control: double (nullable = true)\n",
      " |-- Pedestrian_Crossing_Physical_Facilities: double (nullable = true)\n",
      " |-- Light_Conditions: double (nullable = true)\n",
      " |-- Weather_Conditions: double (nullable = true)\n",
      " |-- Road_Surface_Conditions: double (nullable = true)\n",
      " |-- Special_Conditions_at_Site: double (nullable = true)\n",
      " |-- Carriageway_Hazards: double (nullable = true)\n",
      " |-- Urban_or_Rural_Area: double (nullable = true)\n",
      " |-- Did_Police_Officer_Attend_Scene_of_Accident: double (nullable = true)\n",
      " |-- Year: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-08T19:19:03.236426Z",
     "start_time": "2023-05-08T19:19:02.818037Z"
    }
   },
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(\n",
    "  inputCols=['Location_Easting_OSGR',\n",
    "             'Location_Northing_OSGR',\n",
    "             'Longitude',\n",
    "             'Police_Force',\n",
    "             'Number_of_Vehicles',\n",
    "             'Number_of_Casualties',\n",
    "             'Date',\n",
    "             'Day_of_Week',\n",
    "             'Time',\n",
    "             'Local_Authority_District',\n",
    "             'Local_Authority_Highway',\n",
    "             '1st_Road_Class',\n",
    "             '1st_Road_Number',\n",
    "             'Road_Type',\n",
    "             'Speed_limit',\n",
    "             '2nd_Road_Class',\n",
    "             '2nd_Road_Number',\n",
    "             'Pedestrian_Crossing_Human_Control',\n",
    "             'Pedestrian_Crossing_Physical_Facilities',\n",
    "             'Light_Conditions',\n",
    "             'Weather_Conditions',\n",
    "             'Road_Surface_Conditions',\n",
    "             'Special_Conditions_at_Site',\n",
    "             'Carriageway_Hazards',\n",
    "             'Urban_or_Rural_Area',\n",
    "             'Did_Police_Officer_Attend_Scene_of_Accident',\n",
    "             'Year'],\n",
    "              outputCol=\"features\")\n",
    "\n",
    "output = assembler.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-08T19:19:04.225829Z",
     "start_time": "2023-05-08T19:19:04.219402Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'assembler = VectorAssembler(\\n  inputCols=[\\n             \\'Number_of_Vehicles\\',\\n             \\'Number_of_Casualties\\'],\\n              outputCol=\"features\")\\n\\noutput = assembler.transform(data)'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"assembler = VectorAssembler(\n",
    "  inputCols=[\n",
    "             'Number_of_Vehicles',\n",
    "             'Number_of_Casualties'],\n",
    "              outputCol=\"features\")\n",
    "\n",
    "output = assembler.transform(data)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-08T19:19:06.444116Z",
     "start_time": "2023-05-08T19:19:06.421343Z"
    }
   },
   "outputs": [],
   "source": [
    "categorical_columns = ['Accident_Index']\n",
    "indexer = StringIndexer(inputCol='Accident_Index', outputCol=\"Accident_Index_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-08T19:19:23.918022Z",
     "start_time": "2023-05-08T19:19:10.971469Z"
    }
   },
   "outputs": [],
   "source": [
    "output_fixed = indexer.fit(output).transform(output)\n",
    "final_data = output_fixed.select(\"features\",'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-08T19:19:26.217728Z",
     "start_time": "2023-05-08T19:19:25.824476Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data,test_data = final_data.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-08T19:19:27.319431Z",
     "start_time": "2023-05-08T19:19:27.314660Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier,RandomForestClassifier\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-08T19:19:28.370759Z",
     "start_time": "2023-05-08T19:19:28.328881Z"
    }
   },
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier(labelCol='label',featuresCol='features')\n",
    "rfc = RandomForestClassifier(labelCol='label',featuresCol='features')\n",
    "#gbt = GBTClassifier(labelCol='label',featuresCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-08T19:23:13.332438Z",
     "start_time": "2023-05-08T19:19:29.381634Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1159, in send_command\n",
      "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
      "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 985, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1164, in send_command\n",
      "    \"Error while receiving\", e, proto.ERROR_ON_RECEIVE)\n",
      "py4j.protocol.Py4JNetworkError: Error while receiving\n"
     ]
    },
    {
     "ename": "Py4JError",
     "evalue": "An error occurred while calling o22086.fit",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-e6cb3f0f9ca3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdtc_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrfc_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#gbt_model = gbt.fit(train_data)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    130\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m         \u001b[0mjava_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_copyValues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit_java\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    290\u001b[0m         \"\"\"\n\u001b[1;32m    291\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    334\u001b[0m             raise Py4JError(\n\u001b[1;32m    335\u001b[0m                 \u001b[0;34m\"An error occurred while calling {0}{1}{2}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m                 format(target_id, \".\", name))\n\u001b[0m\u001b[1;32m    337\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0mtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JError\u001b[0m: An error occurred while calling o22086.fit"
     ]
    }
   ],
   "source": [
    "dtc_model = dtc.fit(train_data)\n",
    "rfc_model = rfc.fit(train_data)\n",
    "#gbt_model = gbt.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-08T10:40:51.662562Z",
     "start_time": "2023-05-08T10:40:51.529374Z"
    }
   },
   "outputs": [],
   "source": [
    "dtc_predictions = dtc_model.transform(test_data)\n",
    "rfc_predictions = rfc_model.transform(test_data)\n",
    "#gbt_predictions = gbt_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-08T10:40:52.583289Z",
     "start_time": "2023-05-08T10:40:52.577635Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-08T10:41:00.144744Z",
     "start_time": "2023-05-08T10:41:00.118856Z"
    }
   },
   "outputs": [],
   "source": [
    "# Select (prediction, true label) and compute test error\n",
    "acc_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-08T10:41:21.026152Z",
     "start_time": "2023-05-08T10:41:00.967542Z"
    }
   },
   "outputs": [],
   "source": [
    "dtc_acc = acc_evaluator.evaluate(dtc_predictions)\n",
    "rfc_acc = acc_evaluator.evaluate(rfc_predictions)\n",
    "#gbt_acc = acc_evaluator.evaluate(gbt_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-08T10:41:37.324273Z",
     "start_time": "2023-05-08T10:41:37.315303Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Here are the results!\")\n",
    "print('-'*50)\n",
    "print('A single decision tree had an accuracy of: {0:2.2f}%'.format(dtc_acc*100))\n",
    "print('-'*50)\n",
    "print('A random forest ensemble had an accuracy of: {0:2.2f}%'.format(rfc_acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-08T10:41:40.199896Z",
     "start_time": "2023-05-08T10:41:38.961371Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "        print(cm)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "        horizontalalignment=\"center\",\n",
    "        color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-08T10:42:03.428437Z",
     "start_time": "2023-05-08T10:41:41.564843Z"
    }
   },
   "outputs": [],
   "source": [
    "#Get Class labels\n",
    "class_temp_dtc = dtc_predictions.select(\"label\").groupBy(\"label\").count().sort('label', ascending=False).toPandas()\n",
    "print(class_temp_dtc)\n",
    "class_temp_rtc = rfc_predictions.select(\"label\").groupBy(\"label\").count().sort('label', ascending=False).toPandas()\n",
    "print(class_temp_rtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-08T10:42:21.636269Z",
     "start_time": "2023-05-08T10:42:07.024261Z"
    }
   },
   "outputs": [],
   "source": [
    "#Calculate confusion matrix for dtc\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_true = dtc_predictions.select(\"label\")\n",
    "y_true = y_true.toPandas()\n",
    "y_pred = dtc_predictions.select(\"prediction\")\n",
    "y_pred = y_pred.toPandas()\n",
    "cnf_matrix = confusion_matrix(y_true, y_pred,labels=class_temp_dtc['label'])\n",
    "cnf_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-08T10:42:22.645388Z",
     "start_time": "2023-05-08T10:42:21.638569Z"
    }
   },
   "outputs": [],
   "source": [
    "#Plotting Results\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_temp_dtc['label'].values, title='Decision tree confusion matrix, without normalization')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-08T10:42:34.479268Z",
     "start_time": "2023-05-08T10:42:22.717960Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#Calculate confusion matrix for rtc\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_true = rfc_predictions.select(\"label\")\n",
    "y_true = y_true.toPandas()\n",
    "y_pred = rfc_predictions.select(\"prediction\")\n",
    "y_pred = y_pred.toPandas()\n",
    "cnf_matrix = confusion_matrix(y_true, y_pred,labels=class_temp_rtc['label'])\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-08T10:42:34.938953Z",
     "start_time": "2023-05-08T10:42:34.481875Z"
    }
   },
   "outputs": [],
   "source": [
    "#Plotting Results\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_temp_rtc['label'].values, title='Random forest confusion matrix, without normalization')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
